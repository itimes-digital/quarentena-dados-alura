{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuarentenaDados Desafio Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itimes-digital/quarentena-dados-alura/blob/master/QuarentenaDados_Desafio_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPwAb_7p_lK",
        "colab_type": "text"
      },
      "source": [
        "# Desafio #QuarentenaDados\n",
        "\n",
        "Bem-vinda e bem-vindo ao desafio #QuarentenaDados valendo um **Nintendo Switch**!\n",
        "\n",
        "Esse notebook traz informações dos dados e como você deve configurar seu arquivo final para submissão.\n",
        "\n",
        "**Caso queira usar esse notebook como exemplo para desenvolver seu projeto, clique em file e escolha a opção Save a copy in Drive**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0faxOX8rZfp",
        "colab_type": "text"
      },
      "source": [
        "Vamos trabalhar com uma amostra aleatória da base de dados MICRODADOS ENEM 2018, essa amostra é **diferente da apresentada em aula**. Junto com a divulgação do resultado final estaremos disponibilizando o código que gerou os dados para que você possa analisar e reproduzir os datasets. \n",
        "\n",
        "Seu objetivo é prever da melhor forma possível a nota das provas de **linguagens e códigos** (NU_NOTA_LC), dado todas as outras notas. O modelo que tiver o menor **erro quadrático médio (MSE)** vence o desafio.\n",
        "\n",
        "Para o desafio você tem três bases à disposição, duas para desenvolver seu modelo e uma para submissão da predição. As bases são as seguintes:\n",
        "\n",
        "- **dados_treino**: São 1500000 linhas contendo a nota das 4 provas + nota de redação.\n",
        "\n",
        "- **dados_teste**: São 20000 linhas contendo com notas das 4 provas + nota de redação.\n",
        "\n",
        "- **dados_desafioqt**: São 10000 linhas com nota de 3 provas + nota de redação. A nota da prova de **Linguagem e Codigos** (NU_NOTA_LC) não está disponível nessa base.\n",
        "\n",
        "\n",
        "As base **dados_treino e dados_teste**, contém as seguintes colunas; **NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_MT, NU_NOTA_REDACAO, NU_NOTA_LC** (Você pode consultar a aula 5, onde o Guilherme explica o significado das siglas). A coluna que você deve realizar a **previsão** é **NU_NOTA_LC**. Você pode manipular os dados da forma que quiser, o importante é que no final submeta o arquivo com as informações corretas (detalhes da submissão serão discutidos no final deste notebook).\n",
        "\n",
        "A base **dados_desafioqt**, contém as seguintes colunas; **ID, NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_MT, NU_NOTA_REDACAO**. Repare que os dados **NU_NOTA_LC** não estão presentes, essa é justamente a informação que você precisa prever. Nós temos os valores reais das notas, no final do prazo de submissão um script irá avaliar sua previsão e dará uma nota para o seu modelo. Nessa base também temos o **ID**, essa informação é importante para o envio da sua previsão, garanta que a nota prevista corresponda ao respectivo **ID**.\n",
        "\n",
        "Se você está habituado com o desenvolvimento de modelos de ML, repare que essa divisão de dados é exatamente a mesma que Treino, Teste e Validação. \n",
        "\n",
        "Abaixo preparamos um código exemplo para você seguir, sinta-se à vontade para experimentar diversos outros métodos, mas **GARANTA QUE O ARQUIVO DE SUBMISSÃO ESTEJA CONFIGURADO CORRETAMENTE**.\n",
        "\n",
        "Na primeira parte, estamos lendo a base de dados direto de arquivos no github.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6cK3pPodiB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "URI_TREINO = \"https://github.com/tgcsantos/quaretenadados/blob/master/DADOS_TREINO.csv?raw=true\"\n",
        "URI_TESTE = \"https://github.com/tgcsantos/quaretenadados/raw/master/DADOS_TESTE.csv\"\n",
        "URI_DESAFIOQT = \"https://github.com/tgcsantos/quaretenadados/raw/master/DESAFIOQT.csv\"\n",
        "\n",
        "dados_treino = pd.read_csv(URI_TREINO)\n",
        "dados_teste = pd.read_csv(URI_TESTE)\n",
        "dados_desafioqt = pd.read_csv(URI_DESAFIOQT)\n",
        "\n",
        "erro_treino = \"Erro ao carregar dados de treino\"\n",
        "erro_teste = \"Erro ao carregar dados de teste\"\n",
        "erro_desafioqt = \"Erro ao carregar dados de submissão\"\n",
        "\n",
        "assert dados_treino.shape == (150000, 5), erro_treino\n",
        "assert dados_teste.shape == (20000, 5), erro_teste\n",
        "assert dados_desafioqt.shape == (10000, 5), erro_desafioqt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__4ltGhs54mv",
        "colab_type": "text"
      },
      "source": [
        "Agora com as bases de dados lidas, vamos separar as informações de cada dataset. X_treino e Y_treino são as **features**, X_teste e Y_teste são as **labels** a serem previstas.\n",
        "\n",
        "Duas observações nesta parte:\n",
        "\n",
        "- 1° Como já disponibilizamos os dados de treino e teste separados, você não precisa fazer *train_test_split* feito em aula (porém fique à vontade para trabalhar da forma que achar melhor).\n",
        "\n",
        "- 2° Transformamos X_treino, Y_treino, X_teste, Y_teste em arrays numpy. Se você quiser usar uma biblioteca que não aceite dataframe como entrada de dados, já deixamos pronto para você."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wbWpqZgjLx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coluna_label = 'NU_NOTA_LC'\n",
        "coluna_features = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "\n",
        "X_treino = dados_treino[coluna_features].to_numpy()\n",
        "Y_treino = dados_treino[coluna_label].to_numpy()\n",
        "X_teste = dados_teste[coluna_features].to_numpy()\n",
        "Y_teste = dados_teste[coluna_label].to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewf2Px98qBH",
        "colab_type": "text"
      },
      "source": [
        "A seguir criamos um modelo **Dummy** como exemplo e realizamos a avaliação do modelo com o **mean_squared_error**. \n",
        "\n",
        "Você pode usar qualquer algoritmo ou biblioteca para criar seus modelos, mas garanta que fará a avaliação com o mean_squared_error, pois usaremos essa métrica para avaliar sua predição final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGl3rdaptRDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exemplo de classificação com Dummy\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "modelo_dummy = DummyRegressor()\n",
        "modelo_dummy.fit(X_treino, Y_treino)\n",
        "dummy_predicoes = modelo_dummy.predict(X_teste)\n",
        "\n",
        "avaliacao_dummy = mean_squared_error(Y_teste, dummy_predicoes)\n",
        "\n",
        "print(f\"Minha avaliação nos dados de teste foi de {avaliacao_dummy}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KTYF7ntCbWQ",
        "colab_type": "text"
      },
      "source": [
        "Depois que você criou testou e validou seu modelo, chegou a hora de preparar seu arquivo para a submissão do resultado.\n",
        "\n",
        "No código abaixo, estamos realizando a predição das notas de **linguagem e códigos** do dataset **dados_desafioqt**. Feita a previsão, criamos um dataframe novo para a submissão, primeiro crimos a coluna **ID** e adicionamos a coluna **NU_NOTA_LC** com suas respectivas previsões (repare que nosso modelo não alterou as ordens dos ID's, mas se você utilizar algum modelo que embaralhe essa ordem certifique de colocar a previsão correta para o ID correto).\n",
        "\n",
        "Após isso, salvamos o dataframe com ´.to_csv()´ (**importante, passe o parâmetro index=False para `.to_csv()`, caso contrário nosso script não computará sua nota**) no arquivo **PREDICAO_DESAFIOQT.csv (você precisa submeter o arquivo com esse nome, caso contrário nosso script de avaliação não computará sua nota**)  e utilizamos o `files.download` para baixar o arquivo em sua máquina local.\n",
        "\n",
        "Feito tudo isso você está quase pronto para finalizar e submeter seu resultado. Você já baixou os dados, treinou e validou seu modelo, salvou sua previsão **no padrão ideal para submissão** e já está com o modelo baixado em sua máquina. Entretanto, ainda falta um detalhe: no momento de preencher o **forms** você precisa enviar seu código. Caso esteja usando os notebooks do colab siga as seguintes instruções para o download:\n",
        "\n",
        "- Clique em **File** na parte superior esquerda.\n",
        "- Depois selecione a opção **Download .ipynb** (também aceitaremos o .py caso você prefira desenvolver seu projeto em um arquivo python).\n",
        "\n",
        "\n",
        "Pronto agora é só submeter seu resultado e torcer para levar um **Nintendo Switch** para casa.\n",
        "\n",
        "Boa sorte!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5_zbGU1EQm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#atribuir ao MODELO o nome do seu melhor modelo\n",
        "from google.colab import files\n",
        "\n",
        "MODELO = modelo_dummy\n",
        "X_desafioqt = dados_desafioqt[coluna_features].to_numpy()\n",
        "predicao_desafioqt = MODELO.predict(X_desafioqt)\n",
        "\n",
        "\n",
        "desafio_df = pd.DataFrame(dados_desafioqt.ID)\n",
        "desafio_df[coluna_label] = predicao_desafioqt\n",
        "\n",
        "#NÃO TROCAR O NOME DO ARQUIVO DE SAÍDA (PREDICAO_DESAFIO)\n",
        "desafio_df.to_csv('PREDICAO_DESAFIOQT.csv', index=False) \n",
        "files.download('PREDICAO_DESAFIOQT.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lEqFCgcc97u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7e3626af-cad7-4688-9530-32c9b0c29bfe"
      },
      "source": [
        "dados_treino.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NU_NOTA_CN</th>\n",
              "      <th>NU_NOTA_CH</th>\n",
              "      <th>NU_NOTA_LC</th>\n",
              "      <th>NU_NOTA_MT</th>\n",
              "      <th>NU_NOTA_REDACAO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>530.7</td>\n",
              "      <td>586.5</td>\n",
              "      <td>575.9</td>\n",
              "      <td>539.0</td>\n",
              "      <td>520.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>439.4</td>\n",
              "      <td>577.9</td>\n",
              "      <td>440.9</td>\n",
              "      <td>488.7</td>\n",
              "      <td>380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>414.1</td>\n",
              "      <td>548.8</td>\n",
              "      <td>417.2</td>\n",
              "      <td>382.6</td>\n",
              "      <td>600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>407.9</td>\n",
              "      <td>572.7</td>\n",
              "      <td>558.9</td>\n",
              "      <td>595.4</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>617.2</td>\n",
              "      <td>655.7</td>\n",
              "      <td>564.2</td>\n",
              "      <td>660.9</td>\n",
              "      <td>540.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NU_NOTA_CN  NU_NOTA_CH  NU_NOTA_LC  NU_NOTA_MT  NU_NOTA_REDACAO\n",
              "0       530.7       586.5       575.9       539.0            520.0\n",
              "1       439.4       577.9       440.9       488.7            380.0\n",
              "2       414.1       548.8       417.2       382.6            600.0\n",
              "3       407.9       572.7       558.9       595.4            560.0\n",
              "4       617.2       655.7       564.2       660.9            540.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR5WibcSg5N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d52682d-589d-4f99-e6be-e0bad0262a5a"
      },
      "source": [
        "Y_treino"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([575.9, 440.9, 417.2, ..., 582.4, 553.3, 533.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U9fdlmNsA4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb79b8b4-ec44-4760-b8f9-6161f67ee38f"
      },
      "source": [
        "X_treinamento = X_treino\n",
        "Y_treinamento = Y_treino\n",
        "X_classe_teste = X_teste\n",
        "Y_classe_teste = Y_teste\n",
        "Y_classe_teste"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([550. , 406.3, 652.3, ..., 548.6, 496. , 448. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zkUj8CGTS_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8bf2d404-d627-4a19-9bf0-6f1e6d388c33"
      },
      "source": [
        "#dados_treino_ajustado_sem_lc = dados_treino[['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']]\n",
        "#dados_teste_ajustado_sem_lc = dados_teste[['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']]\n",
        "\n",
        "#X_treino = dados_treino[coluna_features].to_numpy()\n",
        "#X_teste = dados_teste[coluna_features].to_numpy()\n",
        "\n",
        "#Y_treino = dados_treino[coluna_label].to_numpy()\n",
        "#Y_teste = dados_teste[coluna_label].to_numpy()\n",
        "\n",
        "X_treinamento = X_treino\n",
        "Y_treinamento = Y_treino\n",
        "X_classe_teste = X_teste\n",
        "Y_classe_teste = Y_teste\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Alterando a escala dos dados para melhor análise do modelo\n",
        "scaler = StandardScaler()\n",
        "#X_treinamento = scaler.fit_transform(X_treinamento)\n",
        "#Y_treinamento = scaler.fit_transform(Y_treinamento)\n",
        "#X_classe_teste = scaler.fit_transform(X_classe_teste)\n",
        "#Y_classe_teste = scaler.fit_transform(Y_classe_teste)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_regressor = RandomForestRegressor(n_estimators=10, \n",
        "                                         max_features='sqrt',\n",
        "                                         max_depth=2, \n",
        "                                         random_state=0,\n",
        "                                         criterion='mse',\n",
        "                                         n_jobs=-1)\n",
        "\n",
        "random_regressor.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "previsoes = random_regressor.predict(X_classe_teste)\n",
        "\n",
        "precisao = random_regressor.score(X_classe_teste, Y_classe_teste)\n",
        "#matriz = confusion_matrix(Y_teste, previsoes)\n",
        "#accuracy_score(y_true, y_pred, normalize=False)\n",
        "\n",
        "print(previsoes)\n",
        "print('---')\n",
        "print(precisao)\n",
        "#[508.67458616 477.04731915 608.76805883 ... 523.98108195 572.51411882\n",
        "# 507.16917297]\n",
        "#[614.31032146 614.31032146 614.31032146 ... 614.31032146 614.31032146\n",
        "# 614.31032146]\n",
        "#[525.87397263 466.98746092 627.32396204 ... 514.45941049 559.46794451\n",
        "# 494.08860823]\n",
        "#[575.9 440.9 417.2 ... 582.4 553.3 533.9]\n",
        "#random_regressor.predict()\n",
        "#dados_desafioqt\n",
        "\n",
        "\n",
        "#from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#avaliacao_dummy = mean_squared_error(Y_classe_teste, dummy_predicoes)\n",
        "\n",
        "#print(f\"Minha avaliação nos dados de teste foi de {avaliacao_dummy}\")\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[508.67458616 477.04731915 608.76805883 ... 523.98108195 572.51411882\n",
            " 507.16917297]\n",
            "---\n",
            "0.529149006119608\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}